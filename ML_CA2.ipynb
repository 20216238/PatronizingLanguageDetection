{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_CA2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wMyt8ETwyAs"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u-rQ2CSwzWM"
      },
      "source": [
        "pip install tensorflow-text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ6zMfU0wzco"
      },
      "source": [
        "pip install tf-models-official"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6AwLZ8CvgXz"
      },
      "source": [
        "#pip install bert\n",
        "pip install bert-for-tf2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGk8xTMbUXIZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import re\n",
        "#from official.nlp import \n",
        "import bert\n",
        "import tensorflow_hub as hub\n",
        "import math\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VEhc3IKWLWC"
      },
      "source": [
        "import random\n",
        "import os\n",
        "from urllib import request\n",
        "import bert"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI1yeVaY6SLb"
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrb9dwBAWDNK",
        "outputId": "609b973d-f311-42f9-ad43-2a1ed9bc7a6c"
      },
      "source": [
        "module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\"\n",
        "module_name = module_url.split('/')[-1]\n",
        "print(f'Fetching {module_url}')\n",
        "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
        "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
        "  a = f.read()\n",
        "  outf.write(a.decode('utf-8'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJkruAfWFn9"
      },
      "source": [
        "from dont_patronize_me import DontPatronizeMe\n",
        "# Initialize a dpm (Don't Patronize Me) object.\n",
        "# It takes two areguments as input: \n",
        "# (1) Path to the training set, which is the root directory of this notebook.\n",
        "# (2) Path to the test set, which will be released when the evaluation phase begins. \n",
        "# For now, you can just use the dataset for Subtask 1, which the code will load without labels.\n",
        "dpm = DontPatronizeMe('.', 'dontpatronizeme_pcl.tsv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "06E4mdPbWFca",
        "outputId": "5169c07f-6fe3-4da5-bdf3-7df51bde6996"
      },
      "source": [
        "# This method loads the subtask 1 data\n",
        "dpm.load_task1()\n",
        "# which we can then access as a dataframe\n",
        "dpm.train_task1_df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>par_id</th>\n",
              "      <th>art_id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>orig_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@@23953477</td>\n",
              "      <td>in-need</td>\n",
              "      <td>in</td>\n",
              "      <td>The ones in need of constant medical care are ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@@4703096</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>jm</td>\n",
              "      <td>NBC and Spanish-language Univision both declin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@@25567226</td>\n",
              "      <td>in-need</td>\n",
              "      <td>hk</td>\n",
              "      <td>A second T-Home project is being launched in t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@@1824078</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>tz</td>\n",
              "      <td>Camfed would like to see this trend reversed ....</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@@1921089</td>\n",
              "      <td>refugee</td>\n",
              "      <td>tz</td>\n",
              "      <td>Kagunga village was reported to lack necessary...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       par_id         art_id keyword  ... text label  orig_label\n",
              "0  @@23953477        in-need      in  ...    0     0           0\n",
              "1   @@4703096      immigrant      jm  ...    0     0           0\n",
              "2  @@25567226        in-need      hk  ...    0     0           0\n",
              "3   @@1824078  poor-families      tz  ...    4     1           4\n",
              "4   @@1921089        refugee      tz  ...    0     0           0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAozirumQek7"
      },
      "source": [
        "getting some grief with the file upload. Also need to figure out what type of l"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvgRI2c5n6wV"
      },
      "source": [
        "data=dpm.train_task1_df"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-7VDs73i96t"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "#from tensorflow.keras.losses import softmax_cross_entropy_with_logits\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFFkbXd5i_At"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_kt3bcVGj1-"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcYoOaWFnYDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "206a2e13-bf09-439d-d02f-d33a7ffc87d1"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N96jvFNv8Ed"
      },
      "source": [
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsgRVBBlVBzt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3dARVciz7it"
      },
      "source": [
        "# Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3uqGI1DGVB5S",
        "outputId": "81fb29d3-2455-4c29-bf02-f57e8f32efa1"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>par_id</th>\n",
              "      <th>art_id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>orig_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@@23953477</td>\n",
              "      <td>in-need</td>\n",
              "      <td>in</td>\n",
              "      <td>The ones in need of constant medical care are ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@@4703096</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>jm</td>\n",
              "      <td>NBC and Spanish-language Univision both declin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@@25567226</td>\n",
              "      <td>in-need</td>\n",
              "      <td>hk</td>\n",
              "      <td>A second T-Home project is being launched in t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@@1824078</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>tz</td>\n",
              "      <td>Camfed would like to see this trend reversed ....</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@@1921089</td>\n",
              "      <td>refugee</td>\n",
              "      <td>tz</td>\n",
              "      <td>Kagunga village was reported to lack necessary...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       par_id         art_id keyword  ... text label  orig_label\n",
              "0  @@23953477        in-need      in  ...    0     0           0\n",
              "1   @@4703096      immigrant      jm  ...    0     0           0\n",
              "2  @@25567226        in-need      hk  ...    0     0           0\n",
              "3   @@1824078  poor-families      tz  ...    4     1           4\n",
              "4   @@1921089        refugee      tz  ...    0     0           0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6M-5cSoYB6i",
        "outputId": "6b8bd506-6e8b-41be-8520-6bd4ee290ed0"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10636"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CrYS9oXrCK8"
      },
      "source": [
        "df = data.drop('par_id', 1)\n",
        "df = df.drop('art_id',1)\n",
        "df = df.drop('keyword',1)\n",
        "df = df.drop('text',1)\n",
        "#df = data.drop('article_id', 1)\n",
        "df = df.rename(columns={'country': 'paragraph'})\n",
        "#again this needs to be fixed but atm it removed the first column"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEEoGM4oom5M"
      },
      "source": [
        "#df = df.drop('paragraph.1',1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pvXy21Mmr_fv",
        "outputId": "c811d2ea-c22f-4d36-b0c4-600eba8da4ac"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "      <th>orig_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The ones in need of constant medical care are ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NBC and Spanish-language Univision both declin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A second T-Home project is being launched in t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Camfed would like to see this trend reversed ....</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kagunga village was reported to lack necessary...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           paragraph  label orig_label\n",
              "0  The ones in need of constant medical care are ...      0          0\n",
              "1  NBC and Spanish-language Univision both declin...      0          0\n",
              "2  A second T-Home project is being launched in t...      0          0\n",
              "3  Camfed would like to see this trend reversed ....      1          4\n",
              "4  Kagunga village was reported to lack necessary...      0          0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsXbC_glvmbm"
      },
      "source": [
        "df=df.dropna()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rGQX6OEuIO-",
        "outputId": "20449bc9-5778-4e96-f1eb-ade353b70178"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10636"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-6uCerAsdQ6"
      },
      "source": [
        "# attempt 29th nov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnI8o4cRsgIz"
      },
      "source": [
        "so following tutorial on this one from here - starting with the data set with only the labels and the paragraphs. completely copied so far, no variables changed etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QvWer6dptcud",
        "outputId": "8a5bda5e-0416-4e21-ffc9-2715ea584363"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>par_id</th>\n",
              "      <th>art_id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>orig_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@@23953477</td>\n",
              "      <td>in-need</td>\n",
              "      <td>in</td>\n",
              "      <td>The ones in need of constant medical care are ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@@4703096</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>jm</td>\n",
              "      <td>NBC and Spanish-language Univision both declin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@@25567226</td>\n",
              "      <td>in-need</td>\n",
              "      <td>hk</td>\n",
              "      <td>A second T-Home project is being launched in t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@@1824078</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>tz</td>\n",
              "      <td>Camfed would like to see this trend reversed ....</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@@1921089</td>\n",
              "      <td>refugee</td>\n",
              "      <td>tz</td>\n",
              "      <td>Kagunga village was reported to lack necessary...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       par_id         art_id keyword  ... text label  orig_label\n",
              "0  @@23953477        in-need      in  ...    0     0           0\n",
              "1   @@4703096      immigrant      jm  ...    0     0           0\n",
              "2  @@25567226        in-need      hk  ...    0     0           0\n",
              "3   @@1824078  poor-families      tz  ...    4     1           4\n",
              "4   @@1921089        refugee      tz  ...    0     0           0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXpEF5WwtelT"
      },
      "source": [
        "df2=data"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYCXld4fspQ7"
      },
      "source": [
        "#df2=df2.drop(\"country\",1)\n",
        "df2=df2.drop(\"art_id\",1)\n",
        "df2=df2.drop(\"par_id\",1)\n",
        "df2=df2.drop(\"keyword\",1)\n",
        "df2=df2.drop(\"text\",1)\n",
        "df2=df2.drop(\"orig_label\",1)\n",
        "df2 = df2.rename(columns={'country': 'paragraph'})"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QnyjxqhJuBQr",
        "outputId": "a2379cdc-3b05-4117-fba3-75fc6a00d4e3"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The ones in need of constant medical care are ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NBC and Spanish-language Univision both declin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A second T-Home project is being launched in t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Camfed would like to see this trend reversed ....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kagunga village was reported to lack necessary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           paragraph  label\n",
              "0  The ones in need of constant medical care are ...      0\n",
              "1  NBC and Spanish-language Univision both declin...      0\n",
              "2  A second T-Home project is being launched in t...      0\n",
              "3  Camfed would like to see this trend reversed ....      1\n",
              "4  Kagunga village was reported to lack necessary...      0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLvgW5bquMn6"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UToUc9_ls2B8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed5GkO7Ms178"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzdhhCUktBLj"
      },
      "source": [
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOUWYMl7s1yr"
      },
      "source": [
        "pars = []\n",
        "sentences = list(df2['paragraph'])\n",
        "for sen in sentences:\n",
        "    pars.append(preprocess_text(sen))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHjJHlaRtLnN"
      },
      "source": [
        "y=df2[\"label\"]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r64PPV9ru03T"
      },
      "source": [
        "# Creating a BERT Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng3YtawHtLem"
      },
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz5Jk09_u3OL"
      },
      "source": [
        "def tokenize_reviews(text_reviews):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE72dP_rwzMa"
      },
      "source": [
        "tokenized_reviews = [tokenize_reviews(review) for review in pars]\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFEb-vfq2UyI"
      },
      "source": [
        "### preparing data for training/testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLEjvqPS2eIo"
      },
      "source": [
        " To train the model, the input sentences should be of equal length. To create sentences of equal length, one way is to pad the shorter sentences by 0s. However, this can result in a sparse matrix contain large number of 0s. The other way is to pad sentences within each batch. Since we will be training the model in batches, we can pad the sentences within the training batch locally depending upon the length of the longest sentence. To do so, we first need to find the length of each sentence.\n",
        "\n",
        "The following script creates a list of lists where each sublist contains tokenized review, the label of the review and the length of the review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsgP9tGSx0Si"
      },
      "source": [
        "reviews_with_len = [[review, y[i], len(review)]\n",
        "                 for i, review in enumerate(tokenized_reviews)]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCjQitleyuhy"
      },
      "source": [
        "random.shuffle(reviews_with_len)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmZH6M-Ju3J0"
      },
      "source": [
        "reviews_with_len.sort(key=lambda x: x[2])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLOOG_Xu209_"
      },
      "source": [
        "Once the reviews are sorted by length, we can remove the length attribute from all the reviews. Execute the following script to do so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqoop4P-2t63"
      },
      "source": [
        "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC5W_CeN29QJ"
      },
      "source": [
        "Once the reviews are sorted we will convert thed dataset so that it can be used to train TensorFlow 2.0 models. Run the following code to convert the sorted dataset into a TensorFlow 2.0-compliant input dataset shape.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6N8nyLC2t1o"
      },
      "source": [
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PsxcGPP3DCE"
      },
      "source": [
        "Finally, we can now pad our dataset for each batch. The batch size we are going to use is 32 which means that after processing 32 reviews, the weights of the neural network will be updated. To pad the reviews locally with respect to batches, execute the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD2tbGyT2tsp"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M6pRFFl3E6j",
        "outputId": "db4633cf-1879-423c-8061-cd50e8373ae7"
      },
      "source": [
        "next(iter(batched_dataset))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 5), dtype=int32, numpy=\n",
              " array([[    0,     0,     0,     0,     0],\n",
              "        [ 8711,     0,     0,     0,     0],\n",
              "        [ 3110, 20625,     0,     0,     0],\n",
              "        [ 7074,  8556,  8711,     0,     0],\n",
              "        [ 9042, 13141,  2336,     0,     0],\n",
              "        [ 1996, 10275, 11560,     0,     0],\n",
              "        [ 3492,  2172, 20625,     0,     0],\n",
              "        [ 2040,  2003, 13141,     0,     0],\n",
              "        [ 3319, 13141,  2375,     0,     0],\n",
              "        [ 2454,  2000,  1996,  9776,     0],\n",
              "        [ 2009,  2074,  3849, 20625,     0],\n",
              "        [ 3579,  2006,  1996, 11573,     0],\n",
              "        [ 6951,  7126,  5700,  8711,     0],\n",
              "        [ 2885,  5391, 16836, 19549,     0],\n",
              "        [ 3554,  2058,  2273,  2308,     0],\n",
              "        [ 8738,  2005,  2308,  2058,     0],\n",
              "        [16836, 19549,  2125,  4977,     0],\n",
              "        [ 2028,  2111,  2035,  7489,     0],\n",
              "        [ 3577, 26001, 16836,  1999,  7095],\n",
              "        [ 3361,  5375,  2000,  3532,  2945],\n",
              "        [20148,  3727,  2695,  2386, 11573],\n",
              "        [16169,  2000,  2495,  2003, 20625],\n",
              "        [ 8131,  2008,  2028,  5683, 20625],\n",
              "        [12052, 16836,  4727,  1999, 16738],\n",
              "        [ 2037, 13141,  3570,  3464, 15704],\n",
              "        [ 3082, 15811, 17552,  2945, 11573],\n",
              "        [25040, 11573,  4279, 16088,  6265],\n",
              "        [14754,  1999,  2342,  1997, 12992],\n",
              "        [ 2844,  2707,  2005,  2308,  3873],\n",
              "        [ 6735,  2008,  2081,  2068,  8711],\n",
              "        [ 2844,  7266,  2681,  2111, 11573],\n",
              "        [ 1049,  9776,  2025,  4039, 22953]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCl8S0-x3VHg"
      },
      "source": [
        "#### seperate training and testing data - bit of a mad way to do it lol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UscZozHb3aSJ"
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvY_eyqy3NmB"
      },
      "source": [
        "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UEMzWDp3miB"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uSESMab3qmu"
      },
      "source": [
        "### creating model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot_11kpk3oxO"
      },
      "source": [
        "this is taken from [here](https://colab.research.google.com/drive/12noBxRkrZnIkHqvmdfFW2TGdOXFtNePM) . has 3 CNN layers. can also use LSTM layers instead and can also increase or decrease the number of layers (all this taken from the link I've been following [hereee](https://stackabuse.com/text-classification-with-bert-tokenizer-and-tf-2-0-in-python/) ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je8ztsRV3Nho"
      },
      "source": [
        "class TEXT_MODEL(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(TEXT_MODEL, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        \n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9o9Jvz64Vzu"
      },
      "source": [
        "### values for model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg4mC_kS3Nc_"
      },
      "source": [
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 2\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjqIkhEA4fQ3"
      },
      "source": [
        "not too sure what the craic is here lol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iekaNTQ74ttk"
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbEPvpgk4Mbw"
      },
      "source": [
        "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A30Y5HC441u2"
      },
      "source": [
        "Before we can actually train the model we need to compile it. The following script compiles the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa7NbILf43B5"
      },
      "source": [
        "if OUTPUT_CLASSES == 2:\n",
        "    text_model.compile(loss=\"binary_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "else:\n",
        "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiEyujLd423e",
        "outputId": "83dd6606-0326-46fc-ecb6-6f85f50234c0"
      },
      "source": [
        "text_model.fit(train_data, epochs=NB_EPOCHS)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "300/300 [==============================] - 48s 154ms/step - loss: 0.3035 - accuracy: 0.9053\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 46s 153ms/step - loss: 0.1659 - accuracy: 0.9358\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 46s 153ms/step - loss: 0.0366 - accuracy: 0.9872\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 46s 152ms/step - loss: 0.0127 - accuracy: 0.9968\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 46s 152ms/step - loss: 0.0083 - accuracy: 0.9975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f539666e350>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWkJCaxf5f7E"
      },
      "source": [
        "now to try the trained model on the testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRAx0Up55fx4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NqoPg5N4MTU",
        "outputId": "ff08547b-7199-4d10-d5ac-32d32498777a"
      },
      "source": [
        "results = text_model.evaluate(test_data)\n",
        "print(results)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 1s 15ms/step - loss: 1.5106 - accuracy: 0.6335\n",
            "[1.5106418132781982, 0.6335227489471436]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_ZuJePs5mFI"
      },
      "source": [
        "### room for improvement - \n",
        "obvo fix up the code so its not plagiarised and its not for movie reviews.\n",
        "also try get a few diff models not just CNN\n",
        "try get it so that it's not just a binary check (e.g. you have the scale from 0 to 4 and not just 0 and 1)\n",
        "64% accuracy is a bit shit too tbh, especially when only 9% of them are patronizing would be wanting 91%+ for it to be better than random guessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvgUg_ZT5lWX",
        "outputId": "8c2ff258-269c-4929-9bb2-86b6e098f36e"
      },
      "source": [
        "len(df2[df2[\"label\"]==1])/len(df2)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09420834900338473"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWjgW6tS3E2k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}