{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed9d07e",
   "metadata": {},
   "source": [
    "# Semeval offense notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a460d91",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be05977",
   "metadata": {},
   "source": [
    "The tasks were given by\n",
    "Sub task 1- offensive language detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce04092",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ef9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '.\\inputDir\\ref'\n",
    "\n",
    "SAVE_PATH = './save'\n",
    "\n",
    "TRAIN_PATH = './inputDir/ref/dontpatronizeme_pcl.tsv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815eaa30",
   "metadata": {},
   "source": [
    "# Function Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81b5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import wordsegment\n",
    "from dont_patronize_me import DontPatronizeMe\n",
    "import copy\n",
    "import datetime\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "from typing import Dict, List\n",
    "from transformers import BertForSequenceClassification, RobertaForSequenceClassification\n",
    "\n",
    "\n",
    "\n",
    "# Local files\n",
    "#python train.py -bs=32 -lr=3e-6 -ep=20 -pa=3 --model=bert --task=a --clip --cuda=1\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, RobertaTokenizer, get_cosine_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ac621",
   "metadata": {},
   "source": [
    "# Utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1a18c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(toSave, filename, mode='wb'):\n",
    "    dirname = os.path.dirname(filename)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    file = open(filename, mode)\n",
    "    pickle.dump(toSave, file)\n",
    "    file.close()\n",
    "\n",
    "def load(filename, mode='rb'):\n",
    "    file = open(filename, mode)\n",
    "    loaded = pickle.load(file)\n",
    "    file.close()\n",
    "    return loaded\n",
    "\n",
    "def tokenizationFunction(sents, pad_token):\n",
    "    sents_padded = []\n",
    "    lens = lensFinderFunction(sents)\n",
    "    max_len = max(lens)\n",
    "    sents_padded = [sents[i] + [pad_token] * (max_len - l) for i, l in enumerate(lens)]\n",
    "    return sents_padded\n",
    "\n",
    "def sortingFunction(sents, reverse=True):\n",
    "    sents.sort(key=(lambda s: len(s)), reverse=reverse)\n",
    "    return sents\n",
    "\n",
    "def maskFinderFunction(sents, unmask_idx=1, mask_idx=0):\n",
    "    lens = lensFinderFunction(sents)\n",
    "    max_len = max(lens)\n",
    "    mask = [([unmask_idx] * l + [mask_idx] * (max_len - l)) for l in lens]\n",
    "    return mask\n",
    "\n",
    "def lensFinderFunction(sents):\n",
    "    return [len(sent) for sent in sents]\n",
    "\n",
    "#def getMaskLength(sents):\n",
    "#    max_len = max([len(sent) for sent in sents])\n",
    "#    return max_len\n",
    "\n",
    "#def truncateLengthArray(sents, length):\n",
    "#    sents = [sent[:length] for sent in sents]\n",
    "#    return sents\n",
    "\n",
    "def get_loss_weight(labels, label_order):\n",
    "    nums = [np.sum(labels == lo) for lo in label_order]\n",
    "    loss_weight = torch.tensor([n / len(labels) for n in nums])\n",
    "    return loss_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3dac77",
   "metadata": {},
   "source": [
    "# Data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87241ec1",
   "metadata": {},
   "source": [
    "Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6010475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import wordsegment\n",
    "from dont_patronize_me import DontPatronizeMe\n",
    "dpm = DontPatronizeMe('.', 'dontpatronizeme_pcl.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef721191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map of label to numerical label:\n",
      "{'Unbalanced_power_relations': 0, 'Shallow_solution': 1, 'Presupposition': 2, 'Authority_voice': 3, 'Metaphors': 4, 'Compassion': 5, 'The_poorer_the_merrier': 6}\n"
     ]
    }
   ],
   "source": [
    "dpm.load_task2()\n",
    "# which we can then access as a dataframe\n",
    "dpm.train_task2_df.head()\n",
    "data2=dpm.train_task2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "048aa91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm = DontPatronizeMe('.', 'dontpatronizeme_pcl.tsv')\n",
    "# This method loads the subtask 1 data\n",
    "dpm.load_task1()\n",
    "\n",
    "# which we can then access as a dataframe\n",
    "dpm.train_task1_df.head()\n",
    "\n",
    "data=dpm.train_task1_df\n",
    "data.rename({'par_id': 'ids', 'country': 'text', 'text': 'numericalLabel', 'label': 'labels'}, axis=1, inplace=True)\n",
    "\n",
    "data['numericalLabel'] = data['numericalLabel'].astype(str).astype('int64')\n",
    "data['numericalLabel']= data['numericalLabel'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efdbe4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.rename({'par_id': 'ids', 'country': 'text', 'text': 'numericalLabel', 'label': 'labels'}, axis=1, inplace=True)\n",
    "\n",
    "label2 = [max(p) for p in data2[\"labels\"]]\n",
    "data2\n",
    "data2['maxLabel'] = label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7330d4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>art_id</th>\n",
       "      <th>numericalLabel</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>maxLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@@14767805</td>\n",
       "      <td>We also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>64</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@@14767805</td>\n",
       "      <td>We also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>358</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@@14767805</td>\n",
       "      <td>We also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@@14767805</td>\n",
       "      <td>We also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>175</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@@14767805</td>\n",
       "      <td>We also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>201</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>@@2559173</td>\n",
       "      <td>Touched much by their plight , Commanding Offi...</td>\n",
       "      <td>homeless</td>\n",
       "      <td>lk</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>@@2559173</td>\n",
       "      <td>Touched much by their plight , Commanding Offi...</td>\n",
       "      <td>homeless</td>\n",
       "      <td>lk</td>\n",
       "      <td>31</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>@@1947926</td>\n",
       "      <td>She reiterated her ministry 's commitment to p...</td>\n",
       "      <td>women</td>\n",
       "      <td>gh</td>\n",
       "      <td>153</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>@@14806326</td>\n",
       "      <td>\" The NDC has always led the way in championin...</td>\n",
       "      <td>disabled</td>\n",
       "      <td>gh</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>@@1789214</td>\n",
       "      <td>Preaching the sermon , the Dean of the St. Pet...</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>gh</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2469 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ids                                             art_id  \\\n",
       "0     @@14767805  We also know that they can benefit by receivin...   \n",
       "1     @@14767805  We also know that they can benefit by receivin...   \n",
       "2     @@14767805  We also know that they can benefit by receivin...   \n",
       "3     @@14767805  We also know that they can benefit by receivin...   \n",
       "4     @@14767805  We also know that they can benefit by receivin...   \n",
       "...          ...                                                ...   \n",
       "2464   @@2559173  Touched much by their plight , Commanding Offi...   \n",
       "2465   @@2559173  Touched much by their plight , Commanding Offi...   \n",
       "2466   @@1947926  She reiterated her ministry 's commitment to p...   \n",
       "2467  @@14806326  \" The NDC has always led the way in championin...   \n",
       "2468   @@1789214  Preaching the sermon , the Dean of the St. Pet...   \n",
       "\n",
       "     numericalLabel keyword text                 labels  maxLabel  \n",
       "0          hopeless      us   64  [1, 0, 0, 0, 0, 0, 0]         1  \n",
       "1          hopeless      us  358  [1, 0, 0, 0, 0, 0, 0]         1  \n",
       "2          hopeless      us    0  [1, 0, 0, 1, 0, 0, 0]         1  \n",
       "3          hopeless      us  175  [1, 0, 0, 0, 0, 0, 0]         1  \n",
       "4          hopeless      us  201  [0, 0, 0, 1, 0, 0, 0]         1  \n",
       "...             ...     ...  ...                    ...       ...  \n",
       "2464       homeless      lk    0  [0, 0, 0, 0, 0, 1, 0]         1  \n",
       "2465       homeless      lk   31  [1, 0, 0, 0, 0, 0, 0]         1  \n",
       "2466          women      gh  153  [1, 0, 0, 0, 0, 0, 0]         1  \n",
       "2467       disabled      gh    2  [1, 0, 0, 0, 0, 0, 0]         1  \n",
       "2468     vulnerable      gh   23  [0, 0, 0, 1, 0, 0, 0]         1  \n",
       "\n",
       "[2469 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c97e508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData2, testData2 = train_test_split(data2, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cf3f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb487115",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm = DontPatronizeMe('.', 'dontpatronizeme_pcl.tsv')\n",
    "# This method loads the subtask 1 data\n",
    "dpm.load_task1()\n",
    "\n",
    "# which we can then access as a dataframe\n",
    "dpm.train_task1_df.head()\n",
    "\n",
    "data=dpm.train_task1_df\n",
    "data.rename({'par_id': 'ids', 'country': 'text', 'text': 'numericalLabel', 'label': 'labels'}, axis=1, inplace=True)\n",
    "\n",
    "data['numericalLabel'] = data['numericalLabel'].astype(str).astype('int64')\n",
    "data['numericalLabel']= data['numericalLabel'].squeeze()\n",
    "\n",
    "trainData, testData = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "wordsegment.load()\n",
    "\n",
    "def readPatronizationFile(filepath: str):\n",
    "    ids = np.array(trainData['ids'].values)\n",
    "    text = np.array(trainData['text'].values)\n",
    "    label_1 = np.array(trainData['labels'].values)\n",
    "    \n",
    "    \n",
    "    # Process text\n",
    "    text = textProcessingFunction(text)\n",
    "    nums = len(trainData)\n",
    "    return ids,nums, text, label_1# title#, label_b, label_c\n",
    "\n",
    "def readPatronizationFile2(filepath: str):\n",
    "    ids = np.array(trainData['ids'].values)\n",
    "    text = np.array(trainData['text'].values)\n",
    "    label_1 = np.array(trainData['numericalLabel'].values)\n",
    "    \n",
    "    \n",
    "    # Process text\n",
    "    text = textProcessingFunction(text)\n",
    "    nums = len(trainData)\n",
    "    return ids,nums, text, label_1# title#, label_b, label_c\n",
    "\n",
    "def testDataCreationFunction(task, tokenizer, truncate=512):\n",
    "    ids = np.array(testData['ids'].values)\n",
    "    texts = np.array(testData['text'].values)\n",
    "    label_1 = np.array(testData['labels'].values)\n",
    "    \n",
    "    # Process text\n",
    "    texts = textProcessingFunction(texts)\n",
    "    nums = len(testData)\n",
    "    token_ids = [tokenizer.encode(text=texts[i], add_special_tokens=True, max_length=truncate) for i in range(nums)]\n",
    "    mask = np.array(maskFinderFunction(token_ids))\n",
    "    lens = lensFinderFunction(token_ids)\n",
    "    token_ids = np.array(tokenizationFunction(token_ids, tokenizer.pad_token_id))\n",
    "\n",
    "    return ids, token_ids, lens, mask, label_1\n",
    "\n",
    "def testDataCreationFunction2(task, tokenizer, truncate=512):\n",
    "    ids = np.array(testData['ids'].values)\n",
    "    texts = np.array(testData['text'].values)\n",
    "    label_1 = np.array(testData['numericalLabel'].values)\n",
    "    \n",
    "    # Process text\n",
    "    texts = textProcessingFunction(texts)\n",
    "    nums = len(testData)\n",
    "    token_ids = [tokenizer.encode(text=texts[i], add_special_tokens=True, max_length=truncate) for i in range(nums)]\n",
    "    mask = np.array(maskFinderFunction(token_ids))\n",
    "    lens = lensFinderFunction(token_ids)\n",
    "    token_ids = np.array(tokenizationFunction(token_ids, tokenizer.pad_token_id))\n",
    "\n",
    "    return ids, token_ids, lens, mask, label_1\n",
    "\n",
    "\n",
    "def textProcessingFunction(textLines):\n",
    "    # Process textLines\n",
    "    #textLines = emoji2word(textLines)\n",
    "    #textLines = replace_rare_words(textLines)\n",
    "    textLines = remove_replicates(textLines)\n",
    "    #textLines = segment_hashtag(textLines)\n",
    "    textLines = remove_useless_punctuation(textLines)\n",
    "    textLines = np.array(textLines)\n",
    "    return textLines\n",
    "\n",
    "#def emoji2word(sents):\n",
    "#    return [emoji.demojize(sent) for sent in sents]\n",
    "\n",
    "def remove_useless_punctuation(sents):\n",
    "    for i, sent in enumerate(sents):\n",
    "        sent = sent.replace(':', ' ')\n",
    "        sent = sent.replace('_', ' ')\n",
    "        sent = sent.replace('...', ' ')\n",
    "        sents[i] = sent\n",
    "    return sents\n",
    "\n",
    "def remove_replicates(sents):\n",
    "    # if there are multiple `@USER` tokens in a tweet, replace it with `@USERS`\n",
    "    # because some textLines contain so many `@USER` which may cause redundant\n",
    "    for i, sent in enumerate(sents):\n",
    "        if sent.find('@USER') != sent.rfind('@USER'):\n",
    "            sents[i] = sent.replace('@USER', '')\n",
    "            sents[i] = '@USERS ' + sents[i]\n",
    "    return sents\n",
    "\n",
    "def all_tasks(filepath: str, tokenizer, truncate=512):\n",
    "    nums, ids, textLines, label_a = readPatronizationFile(filepath)#''', label_b, label_c'''\n",
    "    # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    token_ids = [tokenizer.encode(text=textLines[i], add_special_tokens=True, max_length=truncate) for i in range(nums)]\n",
    "    mask = np.array(maskFinderFunction(token_ids))\n",
    "    lens = lensFinderFunction(token_ids)\n",
    "    token_ids = np.array(tokenizationFunction(token_ids, tokenizer.pad_token_id))\n",
    "\n",
    "    return ids, token_ids, lens, mask, label_a, label_b, label_c\n",
    "\n",
    "#Above will need to be redifined\n",
    "def task_1(filepath: str, tokenizer, truncate=512):\n",
    "    ids,nums, textLines, label_1= readPatronizationFile(filepath)\n",
    "    # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    token_ids = [tokenizer.encode(text=textLines[i], add_special_tokens=True, max_length=truncate) for i in range(nums)]\n",
    "    mask = np.array(maskFinderFunction(token_ids))\n",
    "    lens = lensFinderFunction(token_ids)\n",
    "    token_ids = np.array(tokenizationFunction(token_ids, tokenizer.pad_token_id))\n",
    "\n",
    "    return ids, token_ids, lens, mask, label_1\n",
    "\n",
    "#Below willl need to be fixed up with the other path\n",
    "def task_2(filepath: str, tokenizer, truncate=512):\n",
    "    ids,nums, textLines, label_1  = readPatronizationFile2(filepath)\n",
    "    # Only part of the textLines are useful for task b\n",
    "    token_ids = [tokenizer.encode(text=textLines[i], add_special_tokens=True, max_length=truncate) for i in range(nums)]\n",
    "    mask = np.array(maskFinderFunction(token_ids))\n",
    "    lens = lensFinderFunction(token_ids)\n",
    "    token_ids = np.array(tokenizationFunction(token_ids, tokenizer.pad_token_id))\n",
    "\n",
    "    return ids, token_ids, lens, mask, label_1\n",
    "    '''\n",
    "    useful = label_b != 'NULL'\n",
    "    ids = ids[useful]\n",
    "    textLines = textLines[useful]\n",
    "    label_b = label_b[useful]\n",
    "\n",
    "    nums = len(label_b)\n",
    "    # Tokenize\n",
    "    # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    token_ids = [tokenizer.encode(text=textLines[i], add_special_tokens=True, max_length=truncate) for i in range(nums)]\n",
    "    # Get mask\n",
    "    mask = np.array(maskFinderFunction(token_ids))\n",
    "    # Get lengths\n",
    "    lens = lensFinderFunction(token_ids)\n",
    "    # Pad tokens\n",
    "    token_ids = np.array(tokenizationFunction(token_ids, tokenizer.pad_token_id))\n",
    "\n",
    "    return ids, token_ids, lens, mask, label_b\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac605a4",
   "metadata": {},
   "source": [
    "# Datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf21526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "#from config import LABEL_DICT\n",
    "\n",
    "class PatronizationDataset(Dataset):\n",
    "    def __init__(self, input_ids, lens, mask, labels, task):\n",
    "        self.input_ids = torch.tensor(input_ids)\n",
    "        self.lens = lens\n",
    "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
    "        self.labels = labels\n",
    "        self.task = task\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #this_LABEL_DICT = LABEL_DICT[self.task]\n",
    "        input = self.input_ids[idx]\n",
    "        length = self.lens[idx]\n",
    "        mask = self.mask[idx]\n",
    "        #label = torch.tensor(this_LABEL_DICT[self.labels[idx]])\n",
    "        label = self.labels[idx]\n",
    "        return input, length, mask, label\n",
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"\n",
    "    Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None):\n",
    "        # if indices is not provided,\n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset.labels))) \\\n",
    "            if indices is None else indices\n",
    "\n",
    "        # if num_samples is not provided,\n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "\n",
    "        # distribution of classes in the dataset\n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "\n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)] for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, id_):\n",
    "        return dataset.labels[id_]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2077ca",
   "metadata": {},
   "source": [
    "# trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b310bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    '''\n",
    "    The trainer for training models.\n",
    "    It can be used for both single and multi task training.\n",
    "    Every class function ends with _m is for multi-task training.\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        modelNumber: nn.Module,\n",
    "        epochNumber: int,\n",
    "        dataloaderNumber: Dict[str, DataLoader],\n",
    "        criterionNumber: nn.Module,\n",
    "        loss_weightNumber: List[float],\n",
    "        clipNumber: bool,\n",
    "        optimizerNumber: torch.optim.Optimizer,\n",
    "        schedulerNumber: torch.optim.lr_scheduler,\n",
    "        deviceNumber: str,\n",
    "        patienceNumber: int,\n",
    "        taskName: str,\n",
    "        modelName: str,\n",
    "        seedNumber: int\n",
    "    ):\n",
    "        self.model = modelNumber\n",
    "        self.epochs = epochNumber\n",
    "        self.dataloaders = dataloaderNumber\n",
    "        self.criterion = criterionNumber\n",
    "        self.loss_weights = loss_weightNumber\n",
    "        self.clip = clipNumber\n",
    "        self.optimizer = optimizerNumber\n",
    "        self.scheduler = schedulerNumber\n",
    "        self.device = deviceNumber\n",
    "        self.patience = patienceNumber\n",
    "        self.task_name = taskName\n",
    "        self.model_name = modelName\n",
    "        self.seed = seedNumber\n",
    "        self.datetimestr = datetime.datetime.now().strftime('%Y-%b-%d_%H:%M:%S')\n",
    "\n",
    "        # Evaluation results\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.train_f1 = []\n",
    "        self.test_f1 = []\n",
    "        self.best_train_f1 = 0.0\n",
    "        self.best_test_f1 = 0.0\n",
    "\n",
    "        # Evaluation results for multi-task\n",
    "        self.best_train_f1_m = np.array([0, 0, 0], dtype=np.float64)\n",
    "        self.best_test_f1_m = np.array([0, 0, 0], dtype=np.float64)\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'Epoch number {epoch}')\n",
    "            print('=' * 20)\n",
    "            print('/' * 10,'\\\\'*10)\n",
    "            self.trainSingleEpoch()\n",
    "            self.test()\n",
    "            print(f'Best test f1: {self.bestTestF1Score:.4f}')\n",
    "            print('\\\\'*10,'/' * 10)\n",
    "            print('=' * 20)\n",
    "        print('Saving results ...')\n",
    "        save(\n",
    "            (self.trainLosses, self.testingLosses, self.train_f1, self.testF1Score, self.best_train_f1, self.bestTestF1Score),\n",
    "            f'./save/results/single_{self.task_name}_{self.dateTimeString}_{self.bestTestF1Score:.4f}.pt'\n",
    "        )\n",
    "\n",
    "    def trainSingleEpoch(self):\n",
    "        self.model.train()\n",
    "        dataloader = self.dataloaders['train']\n",
    "        yPredictedValue = None\n",
    "        allLabelsFound = None\n",
    "        loss = 0\n",
    "        iters_per_epoch = 0\n",
    "        for inputs, lens, mask, labels in tqdm(dataloader, desc='Training'):\n",
    "            iters_per_epoch += 1\n",
    "\n",
    "            if allLabelsFound is None:\n",
    "                allLabelsFound = labels.numpy()\n",
    "            else:\n",
    "                allLabelsFound = np.concatenate((allLabelsFound, labels.numpy()))\n",
    "\n",
    "            inputs = inputs.to(device=self.device)\n",
    "            lens = lens.to(device=self.device)\n",
    "            mask = mask.to(device=self.device)\n",
    "            labels = labels.to(device=self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                # Forward\n",
    "                logits = self.model(inputs, lens, mask, labels)\n",
    "                _loss = self.criterion(logits, labels)\n",
    "                loss += _loss.item()\n",
    "                y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "                if yPredictedValue is None:\n",
    "                    yPredictedValue = y_pred\n",
    "                else:\n",
    "                    yPredictedValue = np.concatenate((yPredictedValue, y_pred))\n",
    "\n",
    "                # Backward\n",
    "                _loss.backward()\n",
    "                if self.clip:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10)\n",
    "                self.optimizer.step()\n",
    "                if self.scheduler is not None:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "        loss /= iters_per_epoch\n",
    "        f1 = f1_score(allLabelsFound, yPredictedValue, average='macro')\n",
    "        accuracy = accuracy_score(allLabelsFound, yPredictedValue)\n",
    "        balancedAccuracy = balanced_accuracy_score(allLabelsFound, yPredictedValue)\n",
    "        roc = roc_auc_score(allLabelsFound, yPredictedValue)\n",
    "\n",
    "        #TODO insert other details here\n",
    "        \n",
    "        print(f'loss = {loss:.4f}')\n",
    "        print(f'Macro-F1 = {f1:.4f}')\n",
    "        print(f'Accuracy = {accuracy:.4f}')\n",
    "        print(f'Balanced Accuracy  = {balancedAccuracy:.4f}')\n",
    "        print(f'ROC value = {roc:.4f}')\n",
    "\n",
    "        self.trainLosses.append(loss)\n",
    "        self.train_f1.append(f1)\n",
    "        if f1 > self.best_train_f1:\n",
    "            self.bestTrainF1ScoreFound= f1\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        dataloader = self.dataloaders['test']\n",
    "        yPredictedValue = None\n",
    "        allLabelsFound = None\n",
    "        loss = 0\n",
    "        iters_per_epoch = 0\n",
    "        for inputs, lens, mask, labels in tqdm(dataloader, desc='Testing'):\n",
    "            iters_per_epoch += 1\n",
    "\n",
    "            if allLabelsFound is None:\n",
    "                allLabelsFound = labels.numpy()\n",
    "            else:\n",
    "                allLabelsFound = np.concatenate((allLabelsFound, labels.numpy()))\n",
    "\n",
    "            inputs = inputs.to(device=self.device)\n",
    "            lens = lens.to(device=self.device)\n",
    "            mask = mask.to(device=self.device)\n",
    "            labels = labels.to(device=self.device)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                logits = self.model(inputs, lens, mask, labels)\n",
    "                _loss = self.criterion(logits, labels)\n",
    "                y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "                loss += _loss.item()\n",
    "\n",
    "                if yPredictedValue is None:\n",
    "                    yPredictedValue = y_pred\n",
    "                else:\n",
    "                    yPredictedValue = np.concatenate((yPredictedValue, y_pred))\n",
    "\n",
    "        loss /= iters_per_epoch\n",
    "        f1 = f1_score(allLabelsFound, yPredictedValue, average='macro')\n",
    "        accuracy = accuracy_score(allLabelsFound, yPredictedValue)\n",
    "        balancedAccuracy = balanced_accuracy_score(allLabelsFound, yPredictedValue)\n",
    "        roc = roc_auc_score(allLabelsFound, yPredictedValue)\n",
    "\n",
    "        print(f'loss = {loss:.4f}')\n",
    "        print(f'Macro-F1 = {f1:.4f}')\n",
    "        print(f'Accuracy = {accuracy:.4f}')\n",
    "        print(f'Balanced Accuracy  = {balancedAccuracy:.4f}')\n",
    "        print(f'ROC value = {roc:.4f}')\n",
    "        #TODO Insert other details here\n",
    "        self.testingLosses.append(loss)\n",
    "        self.testF1Score.append(f1)\n",
    "        if f1 > self.bestTestF1Score:\n",
    "            self.bestTestF1Score = f1\n",
    "            self.save_model()\n",
    "\n",
    "    def train_m(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'Epoch {epoch}')\n",
    "            print('=' * 20)\n",
    "            print('/' * 10,'\\\\'*10)\n",
    "            self.trainSingleEpoch_m()\n",
    "            self.test_m()\n",
    "            print(f'Best test results A: {self.bestTestF1Score_m[0]:.4f}')\n",
    "            print(f'Best test results B: {self.bestTestF1Score_m[1]:.4f}')\n",
    "            print(f'Best test results C: {self.bestTestF1Score_m[2]:.4f}')\n",
    "            print('=' * 20)\n",
    "            print('\\\\'*10,'/' * 10)\n",
    "\n",
    "        print('Saving results ...')\n",
    "        save(\n",
    "            (self.trainLosses, self.testingLosses, self.train_f1, self.testF1Score, self.best_train_f1_m, self.bestTestF1Score_m),\n",
    "            f'./save/results/mtl_{self.dateTimeString}_{self.bestTestF1Score_m[0]:.4f}.pt'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d123cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "\n",
    "#from utils import save\n",
    "#from config import LABEL_DICT\n",
    "\n",
    "class Trainer():\n",
    "    '''\n",
    "    The trainer for training models.\n",
    "    It can be used for both single and multi task training.\n",
    "    Every class function ends with _m is for multi-task training.\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        epochs: int,\n",
    "        dataloaders: Dict[str, DataLoader],\n",
    "        criterion: nn.Module,\n",
    "        loss_weights: List[float],\n",
    "        clip: bool,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: torch.optim.lr_scheduler,\n",
    "        device: str,\n",
    "        patience: int,\n",
    "        task_name: str,\n",
    "        model_name: str,\n",
    "        seed: int\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.dataloaders = dataloaders\n",
    "        self.criterion = criterion\n",
    "        self.loss_weights = loss_weights\n",
    "        self.clip = clip\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.patience = patience\n",
    "        self.task_name = task_name\n",
    "        self.model_name = model_name\n",
    "        self.seed = seed\n",
    "        self.datetimestr = datetime.datetime.now().strftime('%Y-%b-%d_%H:%M:%S')\n",
    "\n",
    "        # Evaluation results\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.train_f1 = []\n",
    "        self.test_f1 = []\n",
    "        self.best_train_f1 = 0.0\n",
    "        self.best_test_f1 = 0.0\n",
    "\n",
    "        # Evaluation results for multi-task\n",
    "        self.best_train_f1_m = np.array([0, 0, 0], dtype=np.float64)\n",
    "        self.best_test_f1_m = np.array([0, 0, 0], dtype=np.float64)\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'Epoch {epoch}')\n",
    "            print('=' * 20)\n",
    "            self.trainSingleEpoch()\n",
    "            self.test()\n",
    "            print(f'Best test f1: {self.best_test_f1:.4f}')\n",
    "            print('=' * 20)\n",
    "\n",
    "        print('Saving results ...')\n",
    "        save(\n",
    "            (self.train_losses, self.test_losses, self.train_f1, self.test_f1, self.best_train_f1, self.best_test_f1),\n",
    "            f'./save/results/single_{self.task_name}_{self.datetimestr}_{self.best_test_f1:.4f}.pt'\n",
    "        )\n",
    "\n",
    "    def trainSingleEpoch(self):\n",
    "        self.model.train()\n",
    "        dataloader = self.dataloaders['train']\n",
    "        yPredictedValue = None\n",
    "        allLabelsFound = None\n",
    "        loss = 0\n",
    "        iters_per_epoch = 0\n",
    "        for inputs, lens, mask, labels in tqdm(dataloader, desc='Training'):\n",
    "            iters_per_epoch += 1\n",
    "\n",
    "            if allLabelsFound is None:\n",
    "                allLabelsFound = labels.numpy()\n",
    "            else:\n",
    "                allLabelsFound = np.concatenate((allLabelsFound, labels.numpy()))\n",
    "\n",
    "            inputs = inputs.to(device=self.device)\n",
    "            lens = lens.to(device=self.device)\n",
    "            mask = mask.to(device=self.device)\n",
    "            labels = labels.to(device=self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                # Forward\n",
    "                logits = self.model(inputs, lens, mask, labels)\n",
    "                _loss = self.criterion(logits, labels)\n",
    "                loss += _loss.item()\n",
    "                y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "                if yPredictedValue is None:\n",
    "                    yPredictedValue = y_pred\n",
    "                else:\n",
    "                    yPredictedValue = np.concatenate((yPredictedValue, y_pred))\n",
    "\n",
    "                # Backward\n",
    "                _loss.backward()\n",
    "                if self.clip:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10)\n",
    "                self.optimizer.step()\n",
    "                if self.scheduler is not None:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "        loss /= iters_per_epoch\n",
    "        f1 = f1_score(allLabelsFound, yPredictedValue, average='macro')\n",
    "        \n",
    "        print(f'loss = {loss:.4f}')\n",
    "        print(f'Macro-F1 = {f1:.4f}')\n",
    "\n",
    "        self.train_losses.append(loss)\n",
    "        self.train_f1.append(f1)\n",
    "        if f1 > self.best_train_f1:\n",
    "            self.best_train_f1 = f1\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        dataloader = self.dataloaders['test']\n",
    "        yPredictedValue = None\n",
    "        allLabelsFound = None\n",
    "        loss = 0\n",
    "        iters_per_epoch = 0\n",
    "        for inputs, lens, mask, labels in tqdm(dataloader, desc='Testing'):\n",
    "            iters_per_epoch += 1\n",
    "\n",
    "            if allLabelsFound is None:\n",
    "                allLabelsFound = labels.numpy()\n",
    "            else:\n",
    "                allLabelsFound = np.concatenate((allLabelsFound, labels.numpy()))\n",
    "\n",
    "            inputs = inputs.to(device=self.device)\n",
    "            lens = lens.to(device=self.device)\n",
    "            mask = mask.to(device=self.device)\n",
    "            labels = labels.to(device=self.device)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                logits = self.model(inputs, lens, mask, labels)\n",
    "                _loss = self.criterion(logits, labels)\n",
    "                y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "                loss += _loss.item()\n",
    "\n",
    "                if yPredictedValue is None:\n",
    "                    yPredictedValue = y_pred\n",
    "                else:\n",
    "                    yPredictedValue = np.concatenate((yPredictedValue, y_pred))\n",
    "\n",
    "        loss /= iters_per_epoch\n",
    "        f1 = f1_score(allLabelsFound, yPredictedValue, average='macro')\n",
    "        \n",
    "        print(f'loss = {loss:.4f}')\n",
    "        print(f'Macro-F1 = {f1:.4f}')\n",
    "\n",
    "        self.test_losses.append(loss)\n",
    "        self.test_f1.append(f1)\n",
    "        if f1 > self.best_test_f1:\n",
    "            self.best_test_f1 = f1\n",
    "            self.save_model()\n",
    "\n",
    "\n",
    "    def calc_f1(self, labels, y_pred):\n",
    "        return np.array([\n",
    "            f1_score(labels.cpu(), y_pred.cpu(), average='macro'),\n",
    "            f1_score(labels.cpu(), y_pred.cpu(), average='micro'),\n",
    "            f1_score(labels.cpu(), y_pred.cpu(), average='weighted')\n",
    "        ], np.float64)\n",
    "\n",
    "    def printing(self, loss, f1):\n",
    "        print(f'loss = {loss:.4f}')\n",
    "        print(f'Macro-F1 = {f1[0]:.4f}')\n",
    "        print(f'Micro-F1 = {f1[1]:.4f}')\n",
    "        print(f'Weighted-F1 = {f1[2]:.4f}')\n",
    "\n",
    "    def save_model(self):\n",
    "        print('Saving model...')\n",
    "        if self.task_name == 'all':\n",
    "            filename = f'./save/models/{self.task_name}_{self.model_name}_{self.best_test_f1_m[0]}_seed{self.seed}.pt'\n",
    "        else:\n",
    "            filename = f'./save/models/{self.task_name}_{self.model_name}_{self.best_test_f1}_seed{self.seed}.pt'\n",
    "        save(copy.deepcopy(self.model.state_dict()), filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59caaa",
   "metadata": {},
   "source": [
    "#  train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a7729",
   "metadata": {},
   "source": [
    "Below works perfectly, Just need to add remaining functions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1767b4",
   "metadata": {},
   "source": [
    "Splitting train.py up and running it line by line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f3129d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_PATH = './inputDir/ref/dontpatronizeme_pcl.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b91ce",
   "metadata": {},
   "source": [
    "# Creation of Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ae64554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BERT(nn.Module):\n",
    "    def __init__(self, model_size, args, num_labels=2):\n",
    "        super(BERT, self).__init__()\n",
    "        self.model = BertForSequenceClassification.from_pretrained(\n",
    "            f'bert-{model_size}-uncased',\n",
    "            num_labels=num_labels,\n",
    "            hidden_dropout_prob=args['hidden_dropout'],\n",
    "            attention_probs_dropout_prob=args['attention_dropout']\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, lens, mask, labels=None):\n",
    "        outputs = self.model(inputs, attention_mask=mask)\n",
    "        logits = outputs[0]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7e0021c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# totalAccuracyList = []\n",
    "totalLossList = []\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    #Values for High Accuracy run\n",
    "    #args = {'cuda':\"1\",'seed':69,'batch_size':32,'learningRate':3e-6,'epochs':20,'patience':3,'model':'bert','task':'a','model_size':'base','truncate':100,'weight_decay':0,'hidden_dropout':0,'attention_dropout':0,'ckpt':'','scheduler':0,'loss_weights':1,'clip':1}\n",
    "    args =  {'cuda':\"1\",'seed':69,'batch_size':32,'learningRate':3e-6,'epochs':10,'patience':5,'model':'bert','task':2,'model_size':'base','truncate':70,'weight_decay':0,'hidden_dropout':0.2,'attention_dropout':0.4,'ckpt':'','scheduler':0,'loss_weights':[1, 1, 1, 1] ,'clip':1}\n",
    "    bs = args['batch_size']\n",
    "    lr = args['learningRate']\n",
    "    task = args['task']\n",
    "    model_name = args['model']\n",
    "    model_size = args['model_size']\n",
    "    truncate = args['truncate']\n",
    "    epochs = args['epochs']\n",
    "    wd = args['weight_decay']\n",
    "    patience = args['patience']\n",
    "\n",
    "\n",
    "    # Fix seed for reproducibility\n",
    "    seed = args['seed']\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Set device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args['cuda']\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    num_labels = 5 if task == 2 else 2\n",
    "\n",
    "    # Set tokenizer for different models\n",
    "    if model_name == 'bert':\n",
    "        if task == 'all':\n",
    "            model = MTL_Transformer_LSTM(model_name, model_size, args=args)\n",
    "        else:\n",
    "            model = BERT(model_size, args=args, num_labels=num_labels)\n",
    "        tokenizer = BertTokenizer.from_pretrained(f'bert-{model_size}-uncased')\n",
    "    elif model_name == 'roberta':\n",
    "        if task == 'all':\n",
    "            model = MTL_Transformer_LSTM(model_name, model_size, args=args)\n",
    "        else:\n",
    "            model = RoBERTa(model_size, args=args, num_labels=num_labels)\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(f'roberta-{model_size}')\n",
    "    elif model_name == 'bert-gate' and task == 'all':\n",
    "        model_name = model_name.replace('-gate', '')\n",
    "        model = GatedModel(model_name, model_size, args=args)\n",
    "        tokenizer = BertTokenizer.from_pretrained(f'bert-{model_size}-uncased')\n",
    "    elif model_name == 'roberta-gate' and task == 'all':\n",
    "        model_name = model_name.replace('-gate', '')\n",
    "        model = GatedModel(model_name, model_size, args=args)\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(f'roberta-{model_size}')\n",
    "    # Move model to correct device\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    if args['ckpt'] != '':   #This can be removed TODO\n",
    "        model.load_state_dict(load(args['ckpt']))\n",
    "    if task in [1, 2]:\n",
    "        data_methods = {1: task_1, 2: task_2}\n",
    "        ids, token_ids, lens, mask, labels = data_methods[task](TRAIN_PATH, tokenizer=tokenizer, truncate=truncate)\n",
    "        test_ids, test_token_ids, test_lens, test_mask, test_labels = testDataCreationFunction(task, tokenizer=tokenizer, truncate=truncate)\n",
    "        _Dataset = PatronizationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f516341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|▎                                                                          | 1/266 [01:52<8:15:49, 112.26s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    datasets = {\n",
    "        'train': _Dataset(\n",
    "            input_ids=token_ids,\n",
    "            lens=lens,\n",
    "            mask=mask,\n",
    "            labels=labels,\n",
    "            task=task\n",
    "        ),\n",
    "        'test': _Dataset(\n",
    "            input_ids=test_token_ids,\n",
    "            lens=test_lens,\n",
    "            mask=test_mask,\n",
    "            labels=test_labels,\n",
    "            task=task\n",
    "        )\n",
    "    }\n",
    "\n",
    "    sampler = ImbalancedDatasetSampler(datasets['train']) if task in [1,2] else None\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(\n",
    "            dataset=datasets['train'],\n",
    "            batch_size=bs,\n",
    "            sampler=sampler\n",
    "        ),\n",
    "        'test': DataLoader(dataset=datasets['test'], batch_size=bs)\n",
    "    }\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    if args['scheduler']:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        # A warmup scheduler\n",
    "        t_total = epochs * len(dataloaders['train'])\n",
    "        warmup_steps = np.ceil(t_total / 10.0) * 2\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=t_total\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        scheduler = None\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        epochs=epochs,\n",
    "        dataloaders=dataloaders,\n",
    "        criterion=criterion,\n",
    "        loss_weights=args['loss_weights'],\n",
    "        clip=args['clip'],\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        patience=patience,\n",
    "        task_name=task,\n",
    "        model_name=model_name,\n",
    "        seed=args['seed']\n",
    "    )\n",
    "\n",
    "    if task in [1,2]:\n",
    "        trainer.train()\n",
    "    else:\n",
    "        trainer.train_m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9ed2fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        4\n",
       "4        0\n",
       "        ..\n",
       "10631    4\n",
       "10632    0\n",
       "10633    0\n",
       "10634    0\n",
       "10635    0\n",
       "Name: numericalLabel, Length: 10636, dtype: int32"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['numericalLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "caee7da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "10631    1\n",
       "10632    0\n",
       "10633    0\n",
       "10634    0\n",
       "10635    0\n",
       "Name: labels, Length: 10636, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02cc400d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
